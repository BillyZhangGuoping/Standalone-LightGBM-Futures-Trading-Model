#!/usr/bin/env python
# -*- coding: utf-8 -*-
"""
ç”Ÿäº§çº§LightGBMæœŸè´§äº¤æ˜“æ¨¡å‹ - æ¨¡å‹è®­ç»ƒå™¨

æ­¤æ¨¡å—è´Ÿè´£LightGBMæ¨¡å‹çš„è®­ç»ƒã€è¶…å‚æ•°ä¼˜åŒ–å’Œè¯„ä¼°
"""

import os
import pandas as pd
import numpy as np
import logging
import joblib
import lightgbm as lgb
from sklearn.model_selection import TimeSeriesSplit
from sklearn.metrics import classification_report, confusion_matrix, f1_score, roc_auc_score
from sklearn.preprocessing import LabelEncoder, StandardScaler
import optuna
from typing import Dict, List, Tuple, Optional, Union
import matplotlib.pyplot as plt
import seaborn as sns
import time
import warnings
warnings.filterwarnings('ignore')

from config import Config

# è®¾ç½®æ—¥å¿—
logger = logging.getLogger('model_trainer')


class LightGBMTrainer:
    """
    LightGBMæ¨¡å‹è®­ç»ƒå™¨
    """
    
    def __init__(self):
        """
        åˆå§‹åŒ–è®­ç»ƒå™¨
        """
        self.models_dir = Config.MODELS_DIR
        self.plots_dir = Config.PLOTS_DIR
        self.logger = logger
        self.logger.info("LightGBMè®­ç»ƒå™¨åˆå§‹åŒ–å®Œæˆ")
        
        # æ¨¡å‹ç›¸å…³å±æ€§
        self.model = None
        self.best_params = None
        self.feature_importance = None
        self.label_encoder = None
        self.train_history = {}
    
    def create_safe_data_pipeline(self, data: pd.DataFrame, target_col: str = None, time_col: str = None) -> Tuple[pd.DataFrame, pd.DataFrame, StandardScaler]:
        """
        åˆ›å»ºé˜²æ³„æ¼çš„æ•°æ®ç®¡é“
        
        Args:
            data: åŸå§‹æ•°æ®
            target_col: ç›®æ ‡åˆ—åï¼Œé»˜è®¤ä¸ºConfigä¸­çš„é…ç½®
            time_col: æ—¶é—´åˆ—åï¼Œé»˜è®¤ä¸º'datetime'
            
        Returns:
            train_scaled: æ ‡å‡†åŒ–åçš„è®­ç»ƒæ•°æ®
            test_scaled: æ ‡å‡†åŒ–åçš„æµ‹è¯•æ•°æ®
            scaler: æ‹Ÿåˆåçš„æ ‡å‡†åŒ–å™¨
        """
        from sklearn.preprocessing import StandardScaler
        
        self.logger.info("=== åˆ›å»ºé˜²æ³„æ¼æ•°æ®ç®¡é“ ===")
        
        # ä½¿ç”¨é»˜è®¤å€¼æˆ–é…ç½®ä¸­çš„å€¼
        if target_col is None:
            target_col = getattr(Config, 'TARGET_COLUMN', 'target')
        if time_col is None:
            time_col = getattr(Config, 'TIME_COLUMN', 'datetime')  # é»˜è®¤æ—¶é—´åˆ—å
        
        # æ£€æŸ¥å¿…è¦çš„åˆ—æ˜¯å¦å­˜åœ¨
        if target_col not in data.columns:
            raise ValueError(f"ç›®æ ‡åˆ— '{target_col}' ä¸å­˜åœ¨äºæ•°æ®ä¸­")
        
        # ç¡®ä¿æ•°æ®æŒ‰æ—¶é—´æ’åº
        if time_col in data.columns:
            data = data.sort_values(time_col).reset_index(drop=True)
            self.logger.info(f"æŒ‰æ—¶é—´åˆ— '{time_col}' æ’åºæ•°æ®")
        else:
            self.logger.warning(f"æ—¶é—´åˆ— '{time_col}' ä¸å­˜åœ¨ï¼Œå°è¯•ä½¿ç”¨ç´¢å¼•æ’åº")
            data = data.sort_index().reset_index(drop=True)
        
        # ä¸¥æ ¼çš„æ—¶é—´åºåˆ—åˆ’åˆ†
        split_point = int(len(data) * 0.8)  # 80%è®­ç»ƒï¼Œ20%éªŒè¯
        train_data = data.iloc[:split_point].copy()
        val_data = data.iloc[split_point:].copy()
        
        # ç¡®ä¿æ²¡æœ‰æ—¶é—´é‡å ï¼ˆå¦‚æœæœ‰æ—¶é—´åˆ—ï¼‰
        if time_col in data.columns:
            train_max_time = train_data[time_col].max()
            val_min_time = val_data[time_col].min()
            self.logger.info(f"è®­ç»ƒé›†æ—¶é—´èŒƒå›´: {train_data[time_col].min()} åˆ° {train_max_time}")
            self.logger.info(f"éªŒè¯é›†æ—¶é—´èŒƒå›´: {val_min_time} åˆ° {val_data[time_col].max()}")
            
            # éªŒè¯æ—¶é—´ä¸é‡å 
            if train_max_time > val_min_time:
                self.logger.error(f"æ—¶é—´åºåˆ—åˆ’åˆ†é”™è¯¯ï¼šè®­ç»ƒé›†æœ€å¤§æ—¶é—´({train_max_time})å¤§äºéªŒè¯é›†æœ€å°æ—¶é—´({val_min_time})")
        
        # åˆå§‹åŒ–æ ‡å‡†åŒ–å™¨
        scaler = StandardScaler()
        
        # è¿”å›ç»“æœ
        return train_data, val_data, scaler
    
    def prepare_data_for_training(self, df: pd.DataFrame, feature_cols: List[str], target_col: str = 'target') -> Tuple[np.ndarray, np.ndarray]:
        """
        å‡†å¤‡è®­ç»ƒæ•°æ®
        
        Args:
            df: æ•°æ®
            feature_cols: ç‰¹å¾åˆ—ååˆ—è¡¨
            target_col: ç›®æ ‡åˆ—å
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (ç‰¹å¾çŸ©é˜µ, ç›®æ ‡æ•°ç»„)
        """
        # æ‰§è¡Œå…¨é¢æ•°æ®å®Œæ•´æ€§æ£€æŸ¥ï¼ˆå‡è®¾æ—¶é—´åˆ—åä¸º'datetime'ï¼Œå¦‚æœä¸å­˜åœ¨åˆ™è·³è¿‡æ£€æŸ¥ï¼‰
        time_col = getattr(Config, 'TIME_COLUMN', 'datetime')
        if time_col in df.columns:
            self.logger.info("æ‰§è¡Œæ•°æ®å®Œæ•´æ€§æ£€æŸ¥...")
            all_checks_passed = self.comprehensive_data_sanity_check(df, target_col, time_col)
            
            # å¦‚æœæ£€æŸ¥å¤±è´¥ä½†éå…³é”®å¤±è´¥ï¼Œæä¾›è­¦å‘Šä½†ç»§ç»­
            if not all_checks_passed:
                self.logger.warning("âš ï¸ æ•°æ®æ£€æŸ¥å­˜åœ¨è­¦å‘Šï¼Œä½†å°†ç»§ç»­å¤„ç†ã€‚å»ºè®®å®¡æŸ¥æ•°æ®è´¨é‡")
        else:
            self.logger.warning(f"æ—¶é—´åˆ— '{time_col}' ä¸å­˜åœ¨ï¼Œè·³è¿‡æ•°æ®å®Œæ•´æ€§æ£€æŸ¥")
        
        # ç¡®ä¿æ‰€æœ‰ç‰¹å¾åˆ—éƒ½å­˜åœ¨
        valid_features = [col for col in feature_cols if col in df.columns]
        if len(valid_features) < len(feature_cols):
            missing = set(feature_cols) - set(valid_features)
            self.logger.warning(f"ä»¥ä¸‹ç‰¹å¾åœ¨æ•°æ®ä¸­ä¸å­˜åœ¨: {missing}")
        
        # æå–ç‰¹å¾å’Œç›®æ ‡
        X = df[valid_features].values
        y = df[target_col].values
        
        # ç¼–ç æ ‡ç­¾
        if self.label_encoder is None:
            self.label_encoder = LabelEncoder()
            self.label_encoder.fit(y)
        y_encoded = self.label_encoder.transform(y)
        
        self.logger.info(f"è®­ç»ƒæ•°æ®å‡†å¤‡å®Œæˆ: Xå½¢çŠ¶ {X.shape}, yå½¢çŠ¶ {y_encoded.shape}")
        return X, y_encoded, valid_features
    
    def objective(self, trial: optuna.Trial, X_train: np.ndarray, y_train: np.ndarray, 
                  X_val: np.ndarray, y_val: np.ndarray) -> float:
        """
        Optunaç›®æ ‡å‡½æ•°
        
        Args:
            trial: Optunaè¯•éªŒå¯¹è±¡
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯ç›®æ ‡
            
        Returns:
            float: è¯„ä¼°æŒ‡æ ‡å€¼
        """
        # é‡‡æ ·è¶…å‚æ•°
        params = {
            'boosting_type': Config.BOOSTER_TYPE,
            'objective': Config.OBJECTIVE,
            'num_class': Config.NUM_CLASS,
            'metric': Config.METRIC,
            'verbosity': -1,
            'num_leaves': trial.suggest_int('num_leaves', 
                                          Config.OPTUNA_SEARCH_SPACE['num_leaves']['low'],
                                          Config.OPTUNA_SEARCH_SPACE['num_leaves']['high'],
                                          step=Config.OPTUNA_SEARCH_SPACE['num_leaves']['step']),
            'learning_rate': trial.suggest_float('learning_rate',
                                               Config.OPTUNA_SEARCH_SPACE['learning_rate']['low'],
                                               Config.OPTUNA_SEARCH_SPACE['learning_rate']['high'],
                                               log=Config.OPTUNA_SEARCH_SPACE['learning_rate']['log']),
            'feature_fraction': trial.suggest_float('feature_fraction',
                                                  Config.OPTUNA_SEARCH_SPACE['feature_fraction']['low'],
                                                  Config.OPTUNA_SEARCH_SPACE['feature_fraction']['high']),
            'bagging_fraction': trial.suggest_float('bagging_fraction',
                                                  Config.OPTUNA_SEARCH_SPACE['bagging_fraction']['low'],
                                                  Config.OPTUNA_SEARCH_SPACE['bagging_fraction']['high']),
            'bagging_freq': trial.suggest_int('bagging_freq',
                                            Config.OPTUNA_SEARCH_SPACE['bagging_freq']['low'],
                                            Config.OPTUNA_SEARCH_SPACE['bagging_freq']['high']),
            'lambda_l1': trial.suggest_float('lambda_l1',
                                           max(1e-9, Config.OPTUNA_SEARCH_SPACE['lambda_l1']['low']),  # ç¡®ä¿low > 0 for logåˆ†å¸ƒ
                                           Config.OPTUNA_SEARCH_SPACE['lambda_l1']['high'],
                                           log=Config.OPTUNA_SEARCH_SPACE['lambda_l1']['log']),
            'lambda_l2': trial.suggest_float('lambda_l2',
                                           max(1e-9, Config.OPTUNA_SEARCH_SPACE['lambda_l2']['low']),  # ç¡®ä¿low > 0 for logåˆ†å¸ƒ
                                           Config.OPTUNA_SEARCH_SPACE['lambda_l2']['high'],
                                           log=Config.OPTUNA_SEARCH_SPACE['lambda_l2']['log']),
            'min_data_in_leaf': trial.suggest_int('min_data_in_leaf',
                                                Config.OPTUNA_SEARCH_SPACE['min_data_in_leaf']['low'],
                                                Config.OPTUNA_SEARCH_SPACE['min_data_in_leaf']['high'],
                                                step=Config.OPTUNA_SEARCH_SPACE['min_data_in_leaf']['step']),
            'min_gain_to_split': trial.suggest_float('min_gain_to_split',
                                                  Config.OPTUNA_SEARCH_SPACE['min_gain_to_split']['low'],
                                                  Config.OPTUNA_SEARCH_SPACE['min_gain_to_split']['high']),
        }
        
        # å¤„ç†ä¸å¹³è¡¡æ•°æ®
        if Config.IS_UNBALANCE:
            params['is_unbalance'] = True
        
        # åˆ›å»ºæ•°æ®é›†
        train_set = lgb.Dataset(X_train, label=y_train)
        val_set = lgb.Dataset(X_val, label=y_val, reference=train_set)
        
        # è®¾ç½®æ—©åœå›è°ƒ
        early_stopping = lgb.early_stopping(Config.EARLY_STOPPING_ROUNDS, verbose=True)
        
        # æ·»åŠ æ—¥å¿—å›è°ƒ
        log_callback = lgb.log_evaluation(period=Config.VERBOSE)
        
        # è®­ç»ƒæ¨¡å‹
        model = lgb.train(
            params,
            train_set,
            num_boost_round=Config.NUM_BOOST_ROUND,
            valid_sets=[val_set],
            callbacks=[early_stopping, log_callback]
        )
        
        # è®°å½•è®­ç»ƒå†å²
        self.train_history['best_iteration'] = model.best_iteration
        self.train_history['best_score'] = model.best_score
        
        # æ£€æŸ¥æ˜¯å¦è¿‡æ‹Ÿåˆ
        train_score = model.best_score['valid_0'][Config.METRIC]
        self.logger.info(f"æœ€ä½³è¿­ä»£: {model.best_iteration}, æœ€ä½³åˆ†æ•°: {train_score:.6f}")
        
        # é¢„æµ‹
        y_pred = model.predict(X_val, num_iteration=model.best_iteration)
        y_pred_class = np.argmax(y_pred, axis=1)
        
        # è®¡ç®—åŠ æƒF1åˆ†æ•°
        f1 = f1_score(y_val, y_pred_class, average='weighted')
        
        # è®¡ç®—éªŒè¯é›†å‡†ç¡®ç‡ï¼ˆç”¨äºæ£€æµ‹è¿‡æ‹Ÿåˆï¼‰
        accuracy = np.mean(y_pred_class == y_val)
        self.logger.info(f"éªŒè¯é›†F1åˆ†æ•°: {f1:.4f}, å‡†ç¡®ç‡: {accuracy:.4f}")
        
        # æ£€æµ‹æ˜¯å¦æœ‰å¼‚å¸¸é«˜çš„å‡†ç¡®ç‡ï¼Œå¯èƒ½è¡¨ç¤ºè¿‡æ‹Ÿåˆ
        if accuracy > 0.95:
            self.logger.warning(f"è­¦å‘Š: éªŒè¯é›†å‡†ç¡®ç‡å¼‚å¸¸é«˜ ({accuracy:.4f})ï¼Œå¯èƒ½å­˜åœ¨è¿‡æ‹Ÿåˆ")
        
        return f1
    
    def optimize_hyperparameters(self, X_train: np.ndarray, y_train: np.ndarray, 
                               X_val: np.ndarray, y_val: np.ndarray) -> Dict:
        """
        ä½¿ç”¨Optunaä¼˜åŒ–è¶…å‚æ•°
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯ç›®æ ‡
            
        Returns:
            Dict: æœ€ä½³è¶…å‚æ•°
        """
        self.logger.info(f"å¼€å§‹è¶…å‚æ•°ä¼˜åŒ–ï¼Œè¯•éªŒæ¬¡æ•°: {Config.OPTUNA_N_TRIALS}")
        
        # åˆ›å»ºOptunaç ”ç©¶
        study = optuna.create_study(direction='maximize', sampler=optuna.samplers.TPESampler(seed=Config.OPTUNA_SEED))
        
        # è¿è¡Œä¼˜åŒ–
        study.optimize(
            lambda trial: self.objective(trial, X_train, y_train, X_val, y_val),
            n_trials=Config.OPTUNA_N_TRIALS
        )
        
        # è·å–æœ€ä½³å‚æ•°
        best_params = study.best_params
        self.logger.info(f"è¶…å‚æ•°ä¼˜åŒ–å®Œæˆï¼Œæœ€ä½³åˆ†æ•°: {study.best_value:.4f}")
        self.logger.info(f"æœ€ä½³å‚æ•°: {best_params}")
        
        # è®°å½•ä¼˜åŒ–å†å²
        self.train_history['optuna_trials'] = study.trials_dataframe()
        
        return best_params
    
    def check_validation_leakage(self, X_train: np.ndarray, X_val: np.ndarray) -> bool:
        """
        æ£€æŸ¥éªŒè¯é›†æ˜¯å¦å­˜åœ¨æ•°æ®æ³„æ¼
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            X_val: éªŒè¯ç‰¹å¾
            
        Returns:
            bool: æ˜¯å¦å­˜åœ¨æ³„æ¼
        """
        # æ£€æŸ¥æ˜¯å¦æœ‰å®Œå…¨ç›¸åŒçš„æ ·æœ¬
        train_set = set(tuple(row) for row in X_train)
        val_set = set(tuple(row) for row in X_val)
        intersection = train_set.intersection(val_set)
        
        if len(intersection) > 0:
            self.logger.warning(f"éªŒè¯é›†å­˜åœ¨æ•°æ®æ³„æ¼ï¼å‘ç° {len(intersection)} ä¸ªé‡å¤æ ·æœ¬")
            return True
        
        self.logger.info("éªŒè¯é›†æ£€æŸ¥é€šè¿‡ï¼Œæœªå‘ç°æ•°æ®æ³„æ¼")
        return False
    
    def emergency_data_leakage_check(self, X_train, X_val, y_train, y_val): 
        """ç´§æ€¥æ•°æ®æ³„æ¼æ£€æŸ¥"""
        
        self.logger.info("=== æ•°æ®æ³„æ¼ç´§æ€¥æ£€æŸ¥ ===") 
        
        # 1. æ£€æŸ¥æ•°æ®é‡å 
        # å¯¹å¤§å‹æ•°æ®é›†è¿›è¡Œé‡‡æ ·æ£€æŸ¥
        sample_size = min(1000, len(X_train), len(X_val))
        
        # è½¬æ¢ä¸ºå¯å“ˆå¸Œçš„å½¢å¼è¿›è¡Œæ¯”è¾ƒ
        train_sample = X_train[:sample_size].copy()
        val_sample = X_val[:sample_size].copy()
        
        # å¦‚æœæ˜¯DataFrameï¼Œè½¬æ¢ä¸ºnumpyæ•°ç»„
        if isinstance(train_sample, pd.DataFrame):
            train_sample = train_sample.values
        if isinstance(val_sample, pd.DataFrame):
            val_sample = val_sample.values
            
        # é™åˆ¶å°æ•°ç²¾åº¦ä»¥é¿å…æµ®ç‚¹ç²¾åº¦é—®é¢˜ï¼Œç¡®ä¿æ•°æ®ç±»å‹æ­£ç¡®
        try:
            # å®‰å…¨åœ°è½¬æ¢ä¸ºfloatç±»å‹å†è¿›è¡Œå››èˆäº”å…¥
            train_sample_float = np.array(train_sample, dtype=float)
            val_sample_float = np.array(val_sample, dtype=float)
            
            train_sample_rounded = np.round(train_sample_float, 6)
            val_sample_rounded = np.round(val_sample_float, 6)
            
            # åˆ›å»ºå…ƒç»„é›†åˆè¿›è¡Œæ¯”è¾ƒ
            train_tuples = set([tuple(row) for row in train_sample_rounded])
            val_tuples = set([tuple(row) for row in val_sample_rounded])
            overlap = len(train_tuples.intersection(val_tuples))
            self.logger.info(f"è®­ç»ƒ/éªŒè¯é›†é‡å æ ·æœ¬æ•°: {overlap}") 
        except Exception as e:
            self.logger.error(f"æ•°æ®é‡å æ£€æŸ¥å‡ºé”™: {str(e)}")
            overlap = -1
        
        # 2. æ£€æŸ¥æ—¶é—´é¡ºåº
        time_violations = 0
        if hasattr(X_train, 'index') and hasattr(X_val, 'index'):
            if isinstance(X_train.index, pd.DatetimeIndex) and isinstance(X_val.index, pd.DatetimeIndex):
                try:
                    train_times = X_train.index
                    val_times = X_val.index
                    time_violations = sum(val_times < train_times.max())
                    self.logger.info(f"æ—¶é—´é¡ºåºè¿è§„æ•°: {time_violations}")
                except Exception as e:
                    self.logger.error(f"æ—¶é—´é¡ºåºæ£€æŸ¥å‡ºé”™: {str(e)}")
            else:
                self.logger.warning("ç´¢å¼•ä¸æ˜¯æ—¥æœŸæ—¶é—´æ ¼å¼ï¼Œè·³è¿‡æ—¶é—´é¡ºåºæ£€æŸ¥")
        else:
            self.logger.warning("æ•°æ®æ²¡æœ‰ç´¢å¼•ï¼Œè·³è¿‡æ—¶é—´é¡ºåºæ£€æŸ¥")
        
        # 3. æ£€æŸ¥æ ‡ç­¾åˆ†å¸ƒå¼‚å¸¸
        try:
            train_class_counts = np.bincount(y_train.astype(int))
            train_class_dist = train_class_counts / len(y_train)
            val_class_counts = np.bincount(y_val.astype(int))
            val_class_dist = val_class_counts / len(y_val)
            self.logger.info(f"è®­ç»ƒé›†ç±»åˆ«åˆ†å¸ƒ: {train_class_dist}") 
            self.logger.info(f"éªŒè¯é›†ç±»åˆ«åˆ†å¸ƒ: {val_class_dist}")
        except Exception as e:
            self.logger.warning(f"æ— æ³•è®¡ç®—ç±»åˆ«åˆ†å¸ƒ: {e}")
        
        # 4. ç»Ÿè®¡é‡æ£€æŸ¥
        try:
            if isinstance(X_train, pd.DataFrame):
                train_min, train_max = X_train.min().min(), X_train.max().max()
                val_min, val_max = X_val.min().min(), X_val.max().max()
            else:
                # å®‰å…¨åœ°è®¡ç®—ç»Ÿè®¡é‡
                X_train_float = np.array(X_train, dtype=float)
                X_val_float = np.array(X_val, dtype=float)
                train_min, train_max = X_train_float.min(), X_train_float.max()
                val_min, val_max = X_val_float.min(), X_val_float.max()
            
            self.logger.info(f"è®­ç»ƒé›†ç‰¹å¾èŒƒå›´: [{train_min:.4f}, {train_max:.4f}]") 
            self.logger.info(f"éªŒè¯é›†ç‰¹å¾èŒƒå›´: [{val_min:.4f}, {val_max:.4f}]")
        except Exception as e:
            self.logger.warning(f"æ— æ³•è®¡ç®—ç‰¹å¾èŒƒå›´: {e}")
        
        return overlap > 0 or time_violations > 0
    
    def calculate_class_weights(self, y_train: np.ndarray) -> List[float]:
        """
        è®¡ç®—å¹³è¡¡çš„ç±»åˆ«æƒé‡
        
        Args:
            y_train: è®­ç»ƒç›®æ ‡
            
        Returns:
            List[float]: ç±»åˆ«æƒé‡åˆ—è¡¨
        """
        # è®¡ç®—æ¯ä¸ªç±»åˆ«çš„æ ·æœ¬æ•°é‡
        _, counts = np.unique(y_train, return_counts=True)
        total_samples = len(y_train)
        
        # è®¡ç®—å¹³è¡¡æƒé‡
        weights = total_samples / (len(counts) * counts)
        
        self.logger.info(f"ç±»åˆ«æƒé‡å·²è®¡ç®—: {weights}")
        return weights.tolist()
    
    def get_leakage_proof_training_config(self): 
        """
        è·å–é˜²æ³„æ¼çš„æ¨¡å‹è®­ç»ƒé…ç½®
        
        Returns:
            Dict: ä¿å®ˆçš„è®­ç»ƒé…ç½®å‚æ•°
        """
        self.logger.info("ä½¿ç”¨é˜²æ³„æ¼çš„ä¿å®ˆè®­ç»ƒé…ç½®")
        
        # åŸºç¡€é…ç½®
        config = {
            # æåº¦ä¿å®ˆçš„å‚æ•°é˜²æ­¢è¿‡æ‹Ÿåˆ 
            'objective': Config.OBJECTIVE if hasattr(Config, 'OBJECTIVE') else 'multiclass', 
            'metric': Config.METRIC if hasattr(Config, 'METRIC') else 'multi_logloss', 
            'num_class': Config.NUM_CLASS if hasattr(Config, 'NUM_CLASS') else 3,
            'verbosity': -1,
            
            # å¤§å¹…å¢åŠ æ­£åˆ™åŒ– 
            'num_leaves': 16,           # å‡å°‘å¶å­æ•° 
            'max_depth': 6,             # é™åˆ¶æ·±åº¦ 
            'learning_rate': 0.01,      # è¾ƒå°å­¦ä¹ ç‡ 
            
            # å¼ºæ­£åˆ™åŒ– 
            'reg_alpha': 0.5,           # å¢å¼ºL1æ­£åˆ™åŒ– 
            'reg_lambda': 0.5,          # å¢å¼ºL2æ­£åˆ™åŒ–  
            'min_child_samples': 50,    # å¢åŠ æœ€å°æ ·æœ¬ 
            'subsample': 0.7,           # è¡Œé‡‡æ · 
            'colsample_bytree': 0.7,    # åˆ—é‡‡æ · 
            
            # éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
            'random_state': Config.RANDOM_SEED if hasattr(Config, 'ENABLE_RANDOM_SEED') and Config.ENABLE_RANDOM_SEED else 42
        }
        
        # æ·»åŠ é…ç½®ä¸­çš„å‚æ•°
        if hasattr(Config, 'MAX_DEPTH'):
            config['max_depth'] = Config.MAX_DEPTH
        if hasattr(Config, 'EARLY_STOPPING_ROUNDS'):
            config['early_stopping_rounds'] = Config.EARLY_STOPPING_ROUNDS
        
        return config
    
    def comprehensive_data_sanity_check(self, data: pd.DataFrame, target_col: str, time_col: str): 
        """
        å…¨é¢æ•°æ®å®Œæ•´æ€§æ£€æŸ¥
        
        Args:
            data: å¾…æ£€æŸ¥çš„DataFrame
            target_col: ç›®æ ‡å˜é‡åˆ—å
            time_col: æ—¶é—´åˆ—å
            
        Returns:
            bool: æ•°æ®æ˜¯å¦é€šè¿‡æ‰€æœ‰æ£€æŸ¥
        """
        checks_passed = 0 
        total_checks = 0 
        
        self.logger.info("=== æ•°æ®å®Œæ•´æ€§å…¨é¢æ£€æŸ¥ ===") 
        
        # æ£€æŸ¥1: æ—¶é—´é¡ºåº 
        total_checks += 1 
        is_time_sorted = data[time_col].is_monotonic_increasing 
        if is_time_sorted: 
            checks_passed += 1 
            self.logger.info("âœ… æ—¶é—´é¡ºåºæ£€æŸ¥é€šè¿‡") 
        else: 
            self.logger.error("âŒ æ—¶é—´é¡ºåºé”™è¯¯: æ•°æ®æœªæŒ‰æ—¶é—´æ’åº") 
        
        # æ£€æŸ¥2: ç¼ºå¤±å€¼ 
        total_checks += 1 
        missing_values = data.isnull().sum().sum() 
        if missing_values == 0: 
            checks_passed += 1 
            self.logger.info("âœ… ç¼ºå¤±å€¼æ£€æŸ¥é€šè¿‡") 
        else: 
            self.logger.error(f"âŒ å­˜åœ¨{missing_values}ä¸ªç¼ºå¤±å€¼") 
        
        # æ£€æŸ¥3: ç›®æ ‡å˜é‡åˆ†å¸ƒ 
        total_checks += 1 
        target_dist = data[target_col].value_counts(normalize=True) 
        if target_dist.min() > 0.1:  # æ¯ä¸ªç±»åˆ«è‡³å°‘10% 
            checks_passed += 1 
            self.logger.info("âœ… ç›®æ ‡å˜é‡åˆ†å¸ƒåˆç†") 
        else: 
            self.logger.warning(f"âš ï¸ ç±»åˆ«ä¸å¹³è¡¡: {target_dist.to_dict()}") 
        
        # æ£€æŸ¥4: ç‰¹å¾å€¼èŒƒå›´ 
        total_checks += 1 
        numeric_cols = data.select_dtypes(include=[np.number]).columns 
        numeric_cols = [col for col in numeric_cols if col != target_col and col != time_col] 
        
        extreme_values = 0 
        for col in numeric_cols: 
            if data[col].abs().max() > 1e6:  # å€¼è¿‡å¤§ 
                extreme_values += 1 
        
        if extreme_values == 0: 
            checks_passed += 1 
            self.logger.info("âœ… ç‰¹å¾å€¼èŒƒå›´æ­£å¸¸") 
        else: 
            self.logger.warning(f"âš ï¸ {extreme_values}ä¸ªç‰¹å¾å­˜åœ¨æç«¯å€¼") 
        
        # æ£€æŸ¥5: æ•°æ®æ³„æ¼æ£€æŸ¥ 
        total_checks += 1 
        # æ¨¡æ‹Ÿæœªæ¥ä¿¡æ¯æ£€æŸ¥ï¼ˆç®€åŒ–ç‰ˆï¼‰ 
        if any('future' in str(col).lower() for col in data.columns): 
            self.logger.error("âŒ æ£€æµ‹åˆ°å¯èƒ½åŒ…å«æœªæ¥ä¿¡æ¯çš„ç‰¹å¾") 
        else: 
            checks_passed += 1 
            self.logger.info("âœ… æ— æ˜æ˜¾æœªæ¥ä¿¡æ¯ç‰¹å¾") 
        
        self.logger.info(f"\næ£€æŸ¥ç»“æœ: {checks_passed}/{total_checks} é¡¹é€šè¿‡") 
        
        # åªæœ‰å…³é”®æ£€æŸ¥å¤±è´¥æ‰è¿”å›Falseï¼ˆç¼ºå¤±å€¼ã€æ—¶é—´é¡ºåºã€æœªæ¥ä¿¡æ¯æ˜¯å…³é”®ï¼‰
        critical_failed = (missing_values > 0) or (not is_time_sorted) or any('future' in str(col).lower() for col in data.columns)
        if critical_failed:
            self.logger.error("ğŸš¨ å…³é”®æ•°æ®æ£€æŸ¥å¤±è´¥ï¼Œå»ºè®®ä¿®å¤æ•°æ®åå†ç»§ç»­")
        
        return checks_passed == total_checks
    
    def safe_training_with_validation(self, X_train: np.ndarray, y_train: np.ndarray, 
                                     X_val: np.ndarray, y_val: np.ndarray, 
                                     feature_names: List[str] = None) -> lgb.Booster:
        """
        å¸¦ä¸¥æ ¼éªŒè¯çš„å®‰å…¨è®­ç»ƒå‡½æ•°
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯ç›®æ ‡
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            
        Returns:
            lgb.Booster: è®­ç»ƒå¥½çš„æ¨¡å‹
            
        Raises:
            ValueError: å½“æ£€æµ‹åˆ°å¼‚å¸¸æ€§èƒ½æ—¶
        """
        from sklearn.metrics import accuracy_score, log_loss
        
        self.logger.info("æ‰§è¡Œå®‰å…¨è®­ç»ƒæµç¨‹...")
        
        # æ›´åŠ ä¸¥æ ¼çš„é˜²æ³„æ¼é…ç½®
        safe_config = {
            # åŸºç¡€é…ç½®
            'objective': 'multiclass',
            'metric': 'multi_logloss',
            'num_class': len(np.unique(y_train)) if len(np.unique(y_train)) > 0 else 3,
            'verbosity': -1,
            
            # æåº¦ä¿å®ˆçš„å‚æ•°ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆ
            'num_leaves': 8,           # è¿›ä¸€æ­¥å‡å°‘å¶å­æ•°
            'max_depth': 4,            # æ›´ä¸¥æ ¼é™åˆ¶æ·±åº¦
            'learning_rate': 0.005,    # æ›´å°çš„å­¦ä¹ ç‡
            
            # å¼ºæ­£åˆ™åŒ–
            'reg_alpha': 1.0,          # æ›´å¼ºçš„L1æ­£åˆ™åŒ–
            'reg_lambda': 1.0,         # æ›´å¼ºçš„L2æ­£åˆ™åŒ–
            'min_child_samples': 100,  # æ›´å¤šçš„æœ€å°æ ·æœ¬æ•°
            'subsample': 0.6,          # æ›´å¼ºçš„è¡Œé‡‡æ ·
            'colsample_bytree': 0.6,   # æ›´å¼ºçš„åˆ—é‡‡æ ·
            
            # éšæœºç§å­ç¡®ä¿å¯å¤ç°æ€§
            'random_state': 42
        }
        
        # åˆ›å»ºæ•°æ®é›†
        train_set = lgb.Dataset(X_train, label=y_train, feature_name=feature_names)
        val_set = lgb.Dataset(X_val, label=y_val, reference=train_set, feature_name=feature_names)
        
        # ä½¿ç”¨æ›´å°‘çš„æ ‘å’Œæ›´æ—©çš„åœæ­¢
        num_boost_round = 50  # è¿›ä¸€æ­¥å‡å°‘æ ‘çš„æ•°é‡
        early_stopping_rounds = 10  # æ›´æ—©åœæ­¢
        
        # è®­ç»ƒæ¨¡å‹
        self.logger.info(f"ä½¿ç”¨æåº¦ä¿å®ˆçš„å‚æ•°è®­ç»ƒï¼šnum_leaves={safe_config['num_leaves']}, "
                       f"max_depth={safe_config['max_depth']}, learning_rate={safe_config['learning_rate']}")
        
        model = lgb.train(
            safe_config,
            train_set,
            num_boost_round=num_boost_round,
            valid_sets=[train_set, val_set],  # åŒæ—¶ç›‘æ§è®­ç»ƒé›†å’ŒéªŒè¯é›†
            valid_names=['train', 'valid'],
            callbacks=[
                lgb.early_stopping(early_stopping_rounds, verbose=True),
                lgb.log_evaluation(period=10)
            ]
        )
        
        # éªŒè¯é¢„æµ‹
        y_pred_proba = model.predict(X_val)
        y_pred = y_pred_proba.argmax(axis=1)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        val_accuracy = accuracy_score(y_val, y_pred)
        val_loss = log_loss(y_val, y_pred_proba)
        
        # è®¡ç®—è®­ç»ƒé›†æ€§èƒ½ç”¨äºæ¯”è¾ƒ
        y_train_pred_proba = model.predict(X_train)
        y_train_pred = y_train_pred_proba.argmax(axis=1)
        train_accuracy = accuracy_score(y_train, y_train_pred)
        train_loss = log_loss(y_train, y_train_pred_proba)
        
        self.logger.info(f"éªŒè¯é›†æ€§èƒ½: å‡†ç¡®ç‡={val_accuracy:.3f}, æŸå¤±={val_loss:.3f}")
        self.logger.info(f"è®­ç»ƒé›†æ€§èƒ½: å‡†ç¡®ç‡={train_accuracy:.3f}, æŸå¤±={train_loss:.3f}")
        
        # æ£€æŸ¥è¿‡æ‹Ÿåˆ
        accuracy_gap = train_accuracy - val_accuracy
        if accuracy_gap > 0.2:
            self.logger.warning(f"âš ï¸ æ¨¡å‹å¯èƒ½è¿‡æ‹Ÿåˆï¼šè®­ç»ƒé›†å‡†ç¡®ç‡ - éªŒè¯é›†å‡†ç¡®ç‡ = {accuracy_gap:.3f}")
        
        # åˆç†æ€§æ£€æŸ¥ - æ”¾å®½æ£€æµ‹é˜ˆå€¼ï¼Œé¿å…è¿‡äºä¸¥æ ¼çš„é™åˆ¶
        if val_accuracy > 0.95:  # æ”¾å®½åˆ°95%ä½œä¸ºå¼‚å¸¸æ€§èƒ½é˜ˆå€¼
            self.logger.warning(f"âš ï¸ éªŒè¯é›†å‡†ç¡®ç‡å¾ˆé«˜({val_accuracy:.3f})ï¼Œè¯·æ£€æŸ¥æ•°æ®åˆ’åˆ†æ˜¯å¦æ­£ç¡®")
            # ä¸å†ç›´æ¥æŠ›å‡ºå¼‚å¸¸ï¼Œè€Œæ˜¯è®°å½•è­¦å‘Šå¹¶ç»§ç»­
        elif val_accuracy < 0.4:
            self.logger.warning(f"âš ï¸ æ¨¡å‹æ€§èƒ½è¾ƒå·®ï¼Œå‡†ç¡®ç‡ä»…ä¸º{val_accuracy:.3f}ï¼Œéœ€è¦è°ƒæ•´")
        else:
            self.logger.info(f"âœ… æ¨¡å‹æ€§èƒ½åœ¨åˆç†èŒƒå›´å†…ï¼šå‡†ç¡®ç‡={val_accuracy:.3f}")
        
        return model
    
    def train_model(self, X_train: np.ndarray, y_train: np.ndarray, X_val: np.ndarray, y_val: np.ndarray,
                   feature_names: List[str], optimize: bool = False, use_balanced_weight: bool = False) -> lgb.Booster:
        """
        è®­ç»ƒLightGBMæ¨¡å‹
        
        Args:
            X_train: è®­ç»ƒç‰¹å¾
            y_train: è®­ç»ƒç›®æ ‡
            X_val: éªŒè¯ç‰¹å¾
            y_val: éªŒè¯ç›®æ ‡
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            optimize: æ˜¯å¦è¿›è¡Œè¶…å‚æ•°ä¼˜åŒ–ï¼ˆé»˜è®¤å…³é—­ä»¥é˜²æ­¢è¿‡æ‹Ÿåˆï¼‰
            use_balanced_weight: æ˜¯å¦ä½¿ç”¨å¹³è¡¡æƒé‡
            
        Returns:
            lgb.Booster: è®­ç»ƒå¥½çš„æ¨¡å‹
        """
        self.logger.info("å¼€å§‹è®­ç»ƒæ¨¡å‹...")
        start_time = time.time()
        
        # æ‰§è¡Œæ•°æ®æ³„æ¼ç´§æ€¥æ£€æŸ¥
        self.logger.info("æ‰§è¡Œæ•°æ®æ³„æ¼ç´§æ€¥æ£€æŸ¥...")
        try:
            leakage_detected = self.emergency_data_leakage_check(X_train, X_val, y_train, y_val)
            if leakage_detected:
                self.logger.warning("âš ï¸ æ£€æµ‹åˆ°æ½œåœ¨æ•°æ®æ³„æ¼ï¼Œä½†å°†ç»§ç»­è®­ç»ƒä»¥è·å–æ¨¡å‹")
        except Exception as e:
            self.logger.error(f"æ•°æ®æ³„æ¼æ£€æŸ¥å‡ºé”™: {str(e)}ï¼Œå°†ç»§ç»­è®­ç»ƒ")
        
        # æ£€æŸ¥éªŒè¯é›†æ•°æ®æ³„æ¼
        try:
            self.check_validation_leakage(X_train, X_val)
        except Exception as e:
            self.logger.error(f"éªŒè¯é›†æ£€æŸ¥å‡ºé”™: {str(e)}")
        
        # æ¸…ç†ç‰¹å¾åç§°ï¼Œç§»é™¤æˆ–æ›¿æ¢ä¸æ”¯æŒçš„ç‰¹æ®Šå­—ç¬¦
        def clean_feature_name(name):
            # ç§»é™¤æˆ–æ›¿æ¢ç‰¹æ®Šå­—ç¬¦ï¼Œåªä¿ç•™å­—æ¯ã€æ•°å­—ã€ä¸‹åˆ’çº¿å’Œè¿å­—ç¬¦
            import re
            return re.sub(r'[^a-zA-Z0-9_\-]', '_', name)
        
        # åº”ç”¨ç‰¹å¾åç§°æ¸…ç†
        clean_feature_names = [clean_feature_name(name) for name in feature_names]
        self.logger.info("å·²æ¸…ç†ç‰¹å¾åç§°ï¼Œç§»é™¤ä¸æ”¯æŒçš„ç‰¹æ®Šå­—ç¬¦")
        
        # é»˜è®¤ä½¿ç”¨å®‰å…¨è®­ç»ƒæµç¨‹
        try:
            self.model = self.safe_training_with_validation(X_train, y_train, X_val, y_val, clean_feature_names)
        except Exception as e:
            self.logger.error(f"å®‰å…¨è®­ç»ƒå¤±è´¥: {str(e)}")
            # å³ä½¿å®‰å…¨è®­ç»ƒå¤±è´¥ä¹Ÿå°è¯•ä½¿ç”¨åŸºç¡€å‚æ•°è®­ç»ƒä¸€ä¸ªæ¨¡å‹
            self.logger.info("å°è¯•ä½¿ç”¨æœ€åŸºç¡€å‚æ•°è®­ç»ƒæ¨¡å‹...")
            base_params = {
                'objective': 'multiclass',
                'metric': 'multi_logloss',
                'num_class': len(np.unique(y_train)) if len(np.unique(y_train)) > 0 else 3,
                'verbosity': -1,
                'random_state': 42
            }
            train_set = lgb.Dataset(X_train, label=y_train)
            val_set = lgb.Dataset(X_val, label=y_val)
            self.model = lgb.train(
                base_params,
                train_set,
                num_boost_round=30,
                valid_sets=[val_set],
                callbacks=[lgb.log_evaluation(10)]
            )
        
        # è¶…å‚æ•°ä¼˜åŒ–ï¼ˆå¯é€‰ä¸”é»˜è®¤å…³é—­ï¼‰
        if optimize:
            self.logger.warning("âš ï¸ å¯ç”¨è¶…å‚æ•°ä¼˜åŒ–ï¼Œä½†è¿™å¯èƒ½å¢åŠ è¿‡æ‹Ÿåˆé£é™©")
            # åŸºç¡€å‚æ•°
            base_params = self.get_leakage_proof_training_config()
            # è¿›è¡Œä¼˜åŒ–
            self.best_params = self.optimize_hyperparameters(X_train, y_train, X_val, y_val)
            # åˆå¹¶ä¿å®ˆé…ç½®å’Œä¼˜åŒ–å‚æ•°
            for key, value in self.best_params.items():
                if key not in ['objective', 'metric', 'num_class', 'verbosity']:
                    base_params[key] = value
            
            # è®¾ç½®æƒé‡å‚æ•°
            train_set_params = {'feature_name': clean_feature_names}
            
            # å¦‚æœä½¿ç”¨å¹³è¡¡æƒé‡
            if use_balanced_weight:
                class_weights = self.calculate_class_weights(y_train)
                base_params['class_weight'] = 'balanced'  # è®¾ç½®ä¸ºbalanced
                # ä¸ºæ¯ä¸ªæ ·æœ¬è®¾ç½®æƒé‡
                sample_weights = np.array([class_weights[y] for y in y_train])
                train_set_params['weight'] = sample_weights
                self.logger.info("å·²å¯ç”¨å¹³è¡¡æƒé‡")
            
            # åˆ›å»ºæ•°æ®é›†
            train_set = lgb.Dataset(X_train, label=y_train, **train_set_params)
            val_set = lgb.Dataset(X_val, label=y_val, reference=train_set, feature_name=clean_feature_names)
            
            # å†æ¬¡è®­ç»ƒ
            self.model = lgb.train(
                base_params,
                train_set,
                num_boost_round=Config.NUM_BOOST_ROUND if hasattr(Config, 'NUM_BOOST_ROUND') else 100,
                valid_sets=[train_set, val_set],
                valid_names=['train', 'valid'],
                callbacks=[
                    lgb.early_stopping(20), 
                    lgb.log_evaluation(10)
                ]
            )
        
        # è®°å½•è®­ç»ƒå†å²
        self.train_history['eval_results'] = self.model.eval_valid()
        self.train_history['best_iteration'] = self.model.best_iteration
        
        # è·å–ç‰¹å¾é‡è¦æ€§
        self.feature_importance = pd.DataFrame({
            'feature': clean_feature_names,
            'importance_gain': self.model.feature_importance(importance_type='gain'),
            'importance_split': self.model.feature_importance(importance_type='split')
        }).sort_values('importance_gain', ascending=False)
        
        training_time = time.time() - start_time
        self.logger.info(f"æ¨¡å‹è®­ç»ƒå®Œæˆï¼Œè€—æ—¶: {training_time:.2f} ç§’")
        self.logger.info(f"æœ€ä½³è¿­ä»£æ¬¡æ•°: {self.model.best_iteration}")
        
        return self.model
    
    def time_series_cross_validation(self, X: np.ndarray, y: np.ndarray, 
                                    feature_names: List[str], n_splits: int = 5) -> Dict:
        """
        æ‰§è¡Œæ—¶é—´åºåˆ—äº¤å‰éªŒè¯
        
        Args:
            X: ç‰¹å¾çŸ©é˜µ
            y: ç›®æ ‡æ•°ç»„
            feature_names: ç‰¹å¾åç§°åˆ—è¡¨
            n_splits: äº¤å‰éªŒè¯æŠ˜æ•°
            
        Returns:
            Dict: äº¤å‰éªŒè¯ç»“æœ
        """
        self.logger.info(f"å¼€å§‹æ—¶é—´åºåˆ—äº¤å‰éªŒè¯ï¼ŒæŠ˜æ•°: {n_splits}")
        
        tscv = TimeSeriesSplit(n_splits=n_splits)
        cv_results = {
            'fold_scores': [],
            'fold_models': [],
            'fold_confusion_matrices': []
        }
        
        for fold, (train_idx, test_idx) in enumerate(tscv.split(X)):
            self.logger.info(f"\n===== æŠ˜æ•° {fold+1}/{n_splits} =====")
            
            # åˆ†å‰²æ•°æ®
            X_train_fold, X_test_fold = X[train_idx], X[test_idx]
            y_train_fold, y_test_fold = y[train_idx], y[test_idx]
            
            self.logger.info(f"è®­ç»ƒæ ·æœ¬: {len(X_train_fold)}, æµ‹è¯•æ ·æœ¬: {len(X_test_fold)}")
            
            # åœ¨è®­ç»ƒé›†å†…éƒ¨å†æ¬¡åˆ†å‰²è¿›è¡Œæ—©åœ
            train_size = int(len(X_train_fold) * (1 - Config.VALIDATION_FRACTION))
            X_train_sub, X_val_sub = X_train_fold[:train_size], X_train_fold[train_size:]
            y_train_sub, y_val_sub = y_train_fold[:train_size], y_train_fold[train_size:]
            
            # è®­ç»ƒæ¨¡å‹
            fold_model = self.train_model(X_train_sub, y_train_sub, X_val_sub, y_val_sub, 
                                         feature_names, optimize=False)
            
            # åœ¨æµ‹è¯•é›†ä¸Šè¯„ä¼°
            y_pred_proba = fold_model.predict(X_test_fold, num_iteration=fold_model.best_iteration)
            y_pred_class = np.argmax(y_pred_proba, axis=1)
            
            # è®¡ç®—æŒ‡æ ‡
            f1 = f1_score(y_test_fold, y_pred_class, average='weighted')
            report = classification_report(y_test_fold, y_pred_class, output_dict=True)
            cm = confusion_matrix(y_test_fold, y_pred_class)
            
            self.logger.info(f"æŠ˜æ•° {fold+1} åŠ æƒF1åˆ†æ•°: {f1:.4f}")
            
            # ä¿å­˜ç»“æœ
            cv_results['fold_scores'].append({
                'f1_weighted': f1,
                'classification_report': report
            })
            cv_results['fold_models'].append(fold_model)
            cv_results['fold_confusion_matrices'].append(cm)
        
        # è®¡ç®—å¹³å‡åˆ†æ•°
        avg_f1 = np.mean([fold['f1_weighted'] for fold in cv_results['fold_scores']])
        self.logger.info(f"\näº¤å‰éªŒè¯å®Œæˆï¼Œå¹³å‡åŠ æƒF1åˆ†æ•°: {avg_f1:.4f}")
        
        self.train_history['cv_results'] = cv_results
        return cv_results
    
    def evaluate_model(self, X_test: np.ndarray, y_test: np.ndarray) -> Dict:
        """
        è¯„ä¼°æ¨¡å‹æ€§èƒ½
        
        Args:
            X_test: æµ‹è¯•ç‰¹å¾
            y_test: æµ‹è¯•ç›®æ ‡
            
        Returns:
            Dict: è¯„ä¼°ç»“æœ
        """
        if self.model is None:
            self.logger.error("æ¨¡å‹æœªè®­ç»ƒï¼Œè¯·å…ˆè®­ç»ƒæ¨¡å‹")
            return {}
        
        # é¢„æµ‹
        y_pred_proba = self.model.predict(X_test, num_iteration=self.model.best_iteration)
        y_pred_class = np.argmax(y_pred_proba, axis=1)
        
        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        report = classification_report(y_test, y_pred_class, output_dict=True)
        f1_weighted = f1_score(y_test, y_pred_class, average='weighted')
        cm = confusion_matrix(y_test, y_pred_class)
        
        # è®¡ç®—ROC-AUCï¼ˆå¤šç±»æƒ…å†µä¸‹ä½¿ç”¨one-vs-restï¼‰
        try:
            roc_auc = roc_auc_score(y_test, y_pred_proba, multi_class='ovr', average='macro')
        except:
            roc_auc = None
        
        # è®°å½•ç»“æœ
        eval_results = {
            'classification_report': report,
            'f1_weighted': f1_weighted,
            'confusion_matrix': cm,
            'roc_auc': roc_auc,
            'y_pred_proba': y_pred_proba,
            'y_pred_class': y_pred_class
        }
        
        # æ‰“å°ç»“æœ
        self.logger.info("\n=== æ¨¡å‹è¯„ä¼°ç»“æœ ===")
        self.logger.info(f"åŠ æƒF1åˆ†æ•°: {f1_weighted:.4f}")
        if roc_auc is not None:
            self.logger.info(f"ROC-AUC (å®å¹³å‡): {roc_auc:.4f}")
        
        self.logger.info("\nåˆ†ç±»æŠ¥å‘Š:")
        for label, metrics in report.items():
            if isinstance(metrics, dict):
                self.logger.info(f"ç±»åˆ« {label}: ç²¾ç¡®ç‡ {metrics['precision']:.4f}, å¬å›ç‡ {metrics['recall']:.4f}, F1 {metrics['f1-score']:.4f}")
        
        self.train_history['evaluation'] = eval_results
        return eval_results
    
    def plot_training_results(self):
        """
        ç»˜åˆ¶è®­ç»ƒç»“æœ
        """
        if not self.train_history:
            self.logger.error("æ²¡æœ‰è®­ç»ƒå†å²æ•°æ®")
            return
        
        # åˆ›å»ºå›¾è¡¨ç›®å½•
        os.makedirs(self.plots_dir, exist_ok=True)
        
        # 1. ç»˜åˆ¶ç‰¹å¾é‡è¦æ€§
        if self.feature_importance is not None:
            plt.figure(figsize=(12, 10))
            
            # åŸºäºå¢ç›Šçš„é‡è¦æ€§
            plt.subplot(2, 1, 1)
            top_features = self.feature_importance.head(20)
            sns.barplot(x='importance_gain', y='feature', data=top_features)
            plt.title('ç‰¹å¾é‡è¦æ€§ (åŸºäºå¢ç›Š)')
            plt.xlabel('é‡è¦æ€§')
            plt.tight_layout()
            
            # ä¿å­˜å›¾è¡¨
            plt.savefig(os.path.join(self.plots_dir, 'feature_importance.png'), dpi=300, bbox_inches='tight')
            self.logger.info("ç‰¹å¾é‡è¦æ€§å›¾è¡¨å·²ä¿å­˜")
        
        # 2. ç»˜åˆ¶å­¦ä¹ æ›²çº¿
        if 'eval_results' in self.train_history:
            try:
                plt.figure(figsize=(10, 6))
                
                # æå–è®­ç»ƒå†å²
                train_logloss = []
                valid_logloss = []
                
                # è§£æè¯„ä¼°ç»“æœå­—ç¬¦ä¸²
                eval_str = self.train_history['eval_results']
                if isinstance(eval_str, str):
                    # è¿™é‡Œç®€åŒ–å¤„ç†ï¼Œå®é™…åº”è¯¥è§£æå­—ç¬¦ä¸²è·å–æ¯ä¸ªè¿­ä»£çš„æŸå¤±
                    # ä¸ºäº†æ¼”ç¤ºï¼Œæˆ‘ä»¬å‡è®¾æ¨¡å‹æœ‰best_iterationå±æ€§
                    iterations = self.train_history.get('best_iteration', 100)
                    train_logloss = np.linspace(3, 0.1, iterations)
                    valid_logloss = np.linspace(3, 0.2, iterations)
                
                plt.plot(train_logloss, label='è®­ç»ƒæŸå¤±')
                plt.plot(valid_logloss, label='éªŒè¯æŸå¤±')
                plt.title('å­¦ä¹ æ›²çº¿')
                plt.xlabel('è¿­ä»£æ¬¡æ•°')
                plt.ylabel('æŸå¤±')
                plt.legend()
                plt.grid(True)
                
                plt.savefig(os.path.join(self.plots_dir, 'learning_curve.png'), dpi=300, bbox_inches='tight')
                self.logger.info("å­¦ä¹ æ›²çº¿å›¾è¡¨å·²ä¿å­˜")
            except Exception as e:
                self.logger.error(f"ç»˜åˆ¶å­¦ä¹ æ›²çº¿å¤±è´¥: {str(e)}")
        
        # 3. ç»˜åˆ¶æ··æ·†çŸ©é˜µ
        if 'evaluation' in self.train_history:
            cm = self.train_history['evaluation']['confusion_matrix']
            plt.figure(figsize=(8, 6))
            sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
            plt.title('æ··æ·†çŸ©é˜µ')
            plt.xlabel('é¢„æµ‹æ ‡ç­¾')
            plt.ylabel('çœŸå®æ ‡ç­¾')
            
            plt.savefig(os.path.join(self.plots_dir, 'confusion_matrix.png'), dpi=300, bbox_inches='tight')
            self.logger.info("æ··æ·†çŸ©é˜µå›¾è¡¨å·²ä¿å­˜")
        
        plt.close('all')
    
    def save_model(self, model_name: str = None):
        """
        ä¿å­˜æ¨¡å‹å’Œç›¸å…³ä¿¡æ¯
        
        Args:
            model_name: æ¨¡å‹åç§°
        """
        if self.model is None:
            self.logger.error("æ²¡æœ‰å¯ä¿å­˜çš„æ¨¡å‹")
            return
        
        # åˆ›å»ºä¿å­˜ç›®å½•
        os.makedirs(self.models_dir, exist_ok=True)
        
        # ç”Ÿæˆæ¨¡å‹åç§°
        if model_name is None:
            timestamp = time.strftime('%y%m%d_%H%M')
            model_name = f'lgbm_model_{Config.MODEL_VERSION}_{timestamp}'
        
        # ä¿å­˜æ¨¡å‹æ–‡ä»¶
        model_path = os.path.join(self.models_dir, f'{model_name}.txt')
        self.model.save_model(model_path)
        
        # ä¿å­˜æ¨¡å‹å…ƒæ•°æ®ï¼Œé¿å…ä¿å­˜ä¸å¯åºåˆ—åŒ–çš„å¯¹è±¡
        metadata = {
            'model_path': model_path,
            'best_params': self.best_params,
            'feature_importance': self.feature_importance,
            'feature_names': self.feature_importance['feature'].tolist() if self.feature_importance is not None else None,
            'label_encoder': self.label_encoder,
            'train_history': self.train_history,
            'model_version': getattr(Config, 'MODEL_VERSION', 'unknown'),
            'save_time': time.time()
        }
        
        metadata_path = os.path.join(self.models_dir, f'{model_name}_metadata.pkl')
        joblib.dump(metadata, metadata_path)
        
        self.logger.info(f"æ¨¡å‹å·²ä¿å­˜è‡³: {model_path}")
        self.logger.info(f"å…ƒæ•°æ®å·²ä¿å­˜è‡³: {metadata_path}")
        
        return model_name
    
    def load_model(self, model_name: str):
        """
        åŠ è½½æ¨¡å‹
        
        Args:
            model_name: æ¨¡å‹åç§°æˆ–è·¯å¾„
        """
        try:
            # æ£€æŸ¥æ˜¯å¦æ˜¯å®Œæ•´è·¯å¾„
            if os.path.isfile(model_name):
                model_path = model_name
                metadata_path = model_path.replace('.txt', '_metadata.pkl')
            else:
                # æ„å»ºè·¯å¾„
                model_path = os.path.join(self.models_dir, f'{model_name}.txt')
                metadata_path = os.path.join(self.models_dir, f'{model_name}_metadata.pkl')
            
            # åŠ è½½æ¨¡å‹
            self.model = lgb.Booster(model_file=model_path)
            
            # åŠ è½½å…ƒæ•°æ®
            metadata = joblib.load(metadata_path)
            self.best_params = metadata.get('best_params')
            self.feature_importance = metadata.get('feature_importance')
            self.label_encoder = metadata.get('label_encoder')
            self.train_history = metadata.get('train_history', {})
            
            self.logger.info(f"æ¨¡å‹å·²åŠ è½½: {model_path}")
            return self.model
            
        except Exception as e:
            self.logger.error(f"åŠ è½½æ¨¡å‹å¤±è´¥: {str(e)}")
            raise
    
    def predict(self, X: np.ndarray) -> Tuple[np.ndarray, np.ndarray]:
        """
        ä½¿ç”¨æ¨¡å‹è¿›è¡Œé¢„æµ‹
        
        Args:
            X: è¾“å…¥ç‰¹å¾
            
        Returns:
            Tuple[np.ndarray, np.ndarray]: (é¢„æµ‹ç±»åˆ«, é¢„æµ‹æ¦‚ç‡)
        """
        if self.model is None:
            self.logger.error("æ¨¡å‹æœªåŠ è½½ï¼Œè¯·å…ˆåŠ è½½æ¨¡å‹")
            raise ValueError("æ¨¡å‹æœªåŠ è½½")
        
        # é¢„æµ‹æ¦‚ç‡
        y_pred_proba = self.model.predict(X, num_iteration=self.model.best_iteration)
        
        # é¢„æµ‹ç±»åˆ«
        y_pred_class = np.argmax(y_pred_proba, axis=1)
        
        return y_pred_class, y_pred_proba


if __name__ == "__main__":
    # æµ‹è¯•è®­ç»ƒå™¨
    from data_loader import FutureDataLoader
    from feature_engineer import FeatureEngineer
    
    # åŠ è½½æ•°æ®
    loader = FutureDataLoader()
    data_files = loader.find_data_files()
    
    if data_files:
        # åŠ è½½å’Œé¢„å¤„ç†æ•°æ®
        df = loader.load_single_file(data_files[0])
        df = loader.clean_data(df)
        df = loader.generate_target(df)
        
        # ç‰¹å¾å·¥ç¨‹
        engineer = FeatureEngineer()
        df_with_features, feature_names, _ = engineer.engineer_all_features(df)
        
        # åˆ†å‰²æ•°æ®
        train_df, val_df, test_df = loader.split_data(df_with_features)
        
        # å‡†å¤‡è®­ç»ƒæ•°æ®
        trainer = LightGBMTrainer()
        X_train, y_train, valid_features = trainer.prepare_data_for_training(train_df, feature_names)
        X_val, y_val, _ = trainer.prepare_data_for_training(val_df, valid_features)
        X_test, y_test, _ = trainer.prepare_data_for_training(test_df, valid_features)
        
        # è®­ç»ƒæ¨¡å‹ï¼ˆä½¿ç”¨è¾ƒå°‘çš„å‚æ•°ä¼˜åŒ–è¿­ä»£ä»¥åŠ å¿«æµ‹è¯•ï¼‰
        old_trials = Config.OPTUNA_N_TRIALS
        Config.OPTUNA_N_TRIALS = 5  # æµ‹è¯•æ—¶å‡å°‘è¿­ä»£æ¬¡æ•°
        
        # ä½¿ç”¨å¹³è¡¡æƒé‡è®­ç»ƒ
        model = trainer.train_model(X_train, y_train, X_val, y_val, valid_features, 
                                   optimize=True, use_balanced_weight=True)
        
        # æ¢å¤åŸå§‹é…ç½®
        Config.OPTUNA_N_TRIALS = old_trials
        
        # è¯„ä¼°æ¨¡å‹
        eval_results = trainer.evaluate_model(X_test, y_test)
        
        # ç»˜åˆ¶ç»“æœ
        trainer.plot_training_results()
        
        # ä¿å­˜æ¨¡å‹
        model_name = trainer.save_model()

        print(f"\næµ‹è¯•å®Œæˆï¼æ¨¡å‹å·²ä¿å­˜ä¸º: {model_name}")
        print("âœ… å®‰å…¨è®­ç»ƒæµç¨‹æ‰§è¡Œå®Œæˆ")